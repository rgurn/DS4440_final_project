<!doctype html>
<html lang="en">
<head>
<title>Analysis of GANs</title>
<meta property="og:title" content=Analysis of GANs" />
<meta name="twitter:title" content="Analysis of GANs" />
<meta name="description" content="Your project about your cool topic described right here." />
<meta property="og:description" content="Your project about your cool topic described right here." />
<meta name="twitter:description" content="Your project about your cool topic described right here." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Analysis of GANs</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2>An Analysis of "GAN Dissection: Visualizing and Understanding Generative Adversarial Networks"</h2>
<p> By: Riya Gurnani and Xinyu Wu
<p> Paper Link: <a href = "https://openreview.net/pdf?id=Hyg_X2C5FX">GAN Dissection: Visualizing and Understanding Generative Adversarial Networks</a></p>
<p> Our Implementation Link: <a href = "https://github.com/rgurn/DS4440_final_project">GitHub (DS4440 Final Project)</a></p>
</div>
</div>
<div class="row">
<div class="col">

<h2>Introduction</h2>
 <p>
 In this project, we delve into generative adversarial networks (GANs) to better visualize and understand them. “GAN Dissection: Visualizing and Understanding Generative Adversarial Networks” by Bau, Strobelt, et al. introduces a framework for visualizing and understanding GANs at multiple levels of abstraction. The paper provides insights into how GANs represent and generate visual context internally which is crucial given their widespread use in real-world applications. We aim to better understand and expand upon the framework from the paper. Gaining deeper insights into these models will allow for improved performance. Our goal is to successfully implement the code from the paper and test the framework on new data to evaluate the behavior of the model across new datasets and layers. This will also provide further insight into their generalization capabilities.
 </p>

<h2>Paper Review</h2>
<p>
While Generative Adversarial Networks (GANs) have proven significant ability to produce realistic images, there is still a gap in understanding how different knowledge and variants affect model performance. Therefore, this paper looks at the internal representations of GANs and how they are structured, including neurons, objects, and contextual relationships between objects. 
</p>
<p>
Objects that are used in this paper include trees, grass, doors, skies, clouds, bricks, and domes. To examine these objects, the paper utilizes representations to denote tensor outputs (r) on each layer of the generator (G) which generates an image (x) through z layers. In relation to units r, the paper understands it in two phases: (1) dissection, (2) intervention. Dissection involves identifying classes that are explicitly represented in r and measuring the relationships between each single unit and their class, c. The latter, intervention, uses the classes found through dissecting r in order to analyze causal relationships between units and object classes by turning on and off various sets of units. 
</p>
<p>
Building on previous literature, the paper uses an intersection-over-union measure that quantitatively measures the spatial agreement between a unit’s threshold featuremap and a concept’s segmentation. Therefore, this metric is able to rank and pair units with the concepts that most closely match. However, outputs generally depend on multiple parts of the representation, and a combination of units must be identified in relation to a specific object. Thus, an ablation and insertion to the decomposed images can help identify the causal relationship between units and classes, or the average causal effect. This effect can be optimized using L2 regularization and stochastic gradient descent to achieve stronger causal effect.
</p>
<p>
The paper has a number of key findings when understanding units between different datasets, layers, and models: (1) individual unit object detectors form, (2) there are interpretable units for different scene categories such as living room and kitchen, (3) different layers have varying interpretable units, and (4) these interpretable units can help differentiate between GAN models. Overall, the paper provides a strong basis to understanding neurons, objects, and their relationships in GAN models by dissecting and intervening with individual layers. 
</p>
 
<h2>Method</h2>
<p>
 Our first step has been to understand the complex framework detailed in the paper and its provided code. It analyzes how objects are encoded within a GAN generator through dissection and intervention. By intervening in the network and observing the effects on generated images, we gain insights into the causal relationships between units and objects. Our first step was to run the framework code and then we will expand on this by introducing new data and evaluating how the model behaves. We are mainly testing with image generation and content manipulation.
</p>

<h2>Findings</h2>
reports your experimental findings. This should include graphs or images that visualize the results that you have obtained. Ideally this will compare your method to some simpler approach.

<h2>Conclusion</h2>
one paragraph to summarize your conclusions, including any implications for applications or impacts on society, or ideas for future work.

<h2>References</h2>
 
 <p>[1] David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B. Tenenbaum, William T. Freeman, Antonio Torralba. GAN Dissection: Visualizing and Understanding Generative Adversarial Networks, Proceedings of the International Conference on Learning Representations (ICLR), 2019.
</p>
 

<h2>Team Members</h2>
 <p>1. Riya Gurnani <a href="gurnani.r@northeastern.edu">(gurnani.r@northeastern.edu</a>)</p>
 <p>2. Xinyu Wu <a href="wu.xinyu2@northeastern.edu">(wu.xinyu2@northeastern.edu</a>)</p>

  
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://ds4440.baulab.info/2024-Spring/">About DS 4440</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>
